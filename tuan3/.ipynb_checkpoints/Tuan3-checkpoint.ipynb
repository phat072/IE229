{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "18521068_TranBinhLuat_Lab_work_3",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Question 1: Implement the MNIST learning and inference program by following the 9th lecture’s slides (copy the program on the slide), and submit the program (.py) and the execution results displayed on the console in a word file."
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-12T15:59:28.141137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "# !pip install torchvision"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting torch\r\n",
      "  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting filelock (from torch)\r\n",
      "  Using cached filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/phan/.local/lib/python3.10/site-packages (from torch) (4.10.0)\r\n",
      "Requirement already satisfied: sympy in /home/phan/.local/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: jinja2 in /home/phan/.local/lib/python3.10/site-packages (from torch) (3.1.3)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\r\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\r\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\r\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\r\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\r\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\r\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\r\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\r\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\r\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\r\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\r\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.2.0 (from torch)\r\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\r\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/phan/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/phan/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\r\n",
      "\u001B[2K   \u001B[91m━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.0/755.5 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:03:25\u001B[0mm"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K1gK-SSMrQ3C",
    "ExecuteTime": {
     "end_time": "2024-04-12T15:59:24.983603Z",
     "start_time": "2024-04-12T15:59:24.810245Z"
    }
   },
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "\n",
    "#download data\n",
    "train_set = MNIST(root = './', train=True, transform= tv.transforms.ToTensor(), download=True)\n",
    "test_set = MNIST(root = './', train=False, transform= tv.transforms.ToTensor(), download=True)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MNIST\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtv\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torchvision'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K35a1FNXv8ww"
   },
   "source": [
    "#load\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=100, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y2nSZgBbwlQf",
    "outputId": "fbddadd8-c31a-4c0b-ea53-98c95f2377ed"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):\n",
    "  print(train_set[i])\n",
    "  plt.imshow(train_set[i][0][0], cmap='gray')\n",
    "  txt = \"label {}\".format(train_set[i][1])\n",
    "  plt.text(2,2,txt,color='white')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3rqBPPikxyHA"
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#build model 2 layers\n",
    "l1 = torch.nn.Linear(784, 300)\n",
    "l2 = torch.nn.Linear(300, 10)\n",
    "\n",
    "param = list(l1.parameters()) + list(l2.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(param)\n",
    "\n",
    "def neural_network_model(x):\n",
    "  h = F.relu(l1(x))\n",
    "  y = l2(h)\n",
    "  return y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEPH0x_qzkZ-",
    "outputId": "8267eecd-e41d-47ce-ca3b-fe859db19053"
   },
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "def train():\n",
    "  for e in range(epoch):\n",
    "    loss = 0\n",
    "    for img, lab in train_loader:\n",
    "      img = img.view(-1, 28 * 28)\n",
    "      optimizer.zero_grad()  #Initialize gradient\n",
    "      y = neural_network_model(img)  #update weigh\n",
    "\n",
    "      BatchLoss = F.cross_entropy(y, lab)  #loss_function\n",
    "      BatchLoss.backward()  #loop \n",
    "      optimizer.step()\n",
    "\n",
    "      loss = loss + BatchLoss.item() #loss value\n",
    "\n",
    "    print(\"epoch: {}, loss: {}\".format(e, loss))\n",
    "\n",
    "train()\n",
    "\n",
    "print(\"{} completed\".format(time.time()-start_time))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLBfq04n5ixy",
    "outputId": "c792ff9d-22ba-41f8-97be-09728a5e0ed4"
   },
   "source": [
    "#test\n",
    "\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "for images, labels in test_loader:\n",
    "  images = images.view(-1, 28*28)\n",
    "  y = neural_network_model(images)\n",
    "  pred_labels = y.max(dim=1)[1]\n",
    "  correct = correct + (pred_labels == labels).sum()\n",
    "\n",
    "print(\"correct: \",correct.item())\n",
    "print(\"total: \",total)\n",
    "print(\"accuracy: \",correct.item()/total)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALAPWfiK7Nk2"
   },
   "source": "### Question 2: The MNIST learning and inference program in the 9th lecture’s slides had an intermediate layer of 300 dimensions. Change the intermediate layer to 800 dimensions, and submit the program (.py) and the execution results shown in the console in a word file. (The error will be greatly reduced compared to the 300-dimensional case. The accuracy will be slightly better, but almost the same.)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E5uM0Zu87erP"
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#build model 2 layers\n",
    "L1 = torch.nn.Linear(784, 800)\n",
    "L2 = torch.nn.Linear(800, 10)\n",
    "\n",
    "param1 = list(L1.parameters()) + list(L2.parameters())\n",
    "\n",
    "optimizer1 = torch.optim.Adam(param1)\n",
    "\n",
    "def neural_network_model_1(x):\n",
    "  h = F.relu(L1(x))\n",
    "  y = L2(h)\n",
    "  return y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maYxnaRJ7zft",
    "outputId": "20d44a56-e6f7-487f-e1cb-f4cc9f668c97"
   },
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "def train():\n",
    "  for e in range(epoch):\n",
    "    loss = 0\n",
    "    for images, labels in train_loader:\n",
    "      images = images.view(-1, 28*28)\n",
    "      optimizer1.zero_grad()  #Initialize gradient\n",
    "      y = neural_network_model_1(images)  #update weigh\n",
    "\n",
    "      batchloss = F.cross_entropy(y, labels)  #loss_function\n",
    "      batchloss.backward()  #loop \n",
    "      optimizer1.step()\n",
    "\n",
    "      loss = loss + batchloss.item() #loss value\n",
    "\n",
    "    print(\"epoch: {}, loss: {}\".format(e, loss))\n",
    "\n",
    "train()\n",
    "\n",
    "print(\"{} completed\".format(time.time()-start_time))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIkrlgyR75kX",
    "outputId": "49f71d03-1200-434a-f600-bed1c510f4ec"
   },
   "source": [
    "#test\n",
    "\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "for images, labels in test_loader:\n",
    "  images = images.view(-1, 28*28)\n",
    "  y = neural_network_model_1(images)\n",
    "  pred_labels = y.max(dim=1)[1]\n",
    "  correct = correct + (pred_labels == labels).sum()\n",
    "\n",
    "print(\"correct: \",correct.item())\n",
    "print(\"total: \",total)\n",
    "print(\"accuracy: \",correct.item()/total)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
